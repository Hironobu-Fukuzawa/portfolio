{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"30d54257-dc20-4174-aa40-84e1f6abc56f","showTitle":false,"title":""},"id":"MkbrHZYEw5Cr"},"outputs":[],"source":["from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"5607f10e-0a58-4330-bbeb-fa1d6863efb1","showTitle":false,"title":""},"id":"2luSAeOXxBiQ"},"outputs":[],"source":["sales_file_location = \"/FileStore/tables/Sales_table.csv\"\n","products_file_location = \"/FileStore/tables/Products_table.csv\"\n","sellers_file_location = \"/FileStore/tables/Sellers_table.csv\"\n","file_type = \"csv\"\n","infer_schema = \"true\"\n","first_row_is_header = \"true\"\n","delimiter = \",\"\n","\n","df_pt = spark.read.format(file_type) \\\n","  .option(\"inferSchema\", infer_schema) \\\n","  .option(\"header\", first_row_is_header) \\\n","  .option(\"sep\", delimiter) \\\n","  .load(products_file_location)\n","\n","df_sales = spark.read.format(file_type) \\\n","  .option(\"inferSchema\", infer_schema) \\\n","  .option(\"header\", first_row_is_header) \\\n","  .option(\"sep\", delimiter) \\\n","  .load(sales_file_location)\n","\n","df_seller = spark.read.format(file_type) \\\n","  .option(\"inferSchema\", infer_schema) \\\n","  .option(\"header\", first_row_is_header) \\\n","  .option(\"sep\", delimiter) \\\n","  .load(sellers_file_location)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"7fb33021-930c-4fa9-b595-4ed83c279ed4","showTitle":false,"title":""},"id":"Ps_v7oTixnQf"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------------+\n","| product_name|\n","+-------------+\n","|product_51270|\n","|product_18759|\n","|product_59652|\n","+-------------+\n","\n"]}],"source":["# (a) Output the top 3 most popular products sold among all sellers [2m]\n","\n","# df_pt.createOrReplaceTempView(\"PT\")\n","# df_sales.createOrReplaceTempView(\"SALES\")\n","# sql_text =\"\"\"\n","# SELECT PT.product_name\n","# FROM PT INNER JOIN SALES ON PT.product_id = SALES.product_id\n","# GROUP BY PT.product_name\n","# ORDER BY SUM(SALES.num_of_items_sold) DESC\n","# LIMIT 3;\n","# \"\"\"\n","# result = spark.sql(sql_text)\n","\n","from pyspark.sql.functions import expr, desc\n","\n","result = df_pt.join(df_sales, \"product_id\")\\\n",".groupBy(\"product_name\")\\\n",".agg(expr(\"sum(num_of_items_sold)\").alias(\"total_number_of_items\"))\\\n",".orderBy(desc(\"total_number_of_items\"))\\\n",".limit(3)\\\n",".select(\"product_name\")\n","\n","result.show()\n","\n","# +-------------+\n","# | product_name|\n","# +-------------+\n","# |product_51270|\n","# |product_18759|\n","# |product_59652|\n","# +-------------+\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"866983b3-8214-4740-8f4d-90e87d1db482","showTitle":false,"title":""},"id":"Ljmb_1OaxC8Q"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------------+\n","| product_name|\n","+-------------+\n","|product_36658|\n","+-------------+\n","\n"]}],"source":["# (b) Output the top most sold product (in terms of quantity) among sellers with seller_id 1 to 10 [2m]\n","# Your table should have 1 column(s): [product_name] \n","\n","from pyspark.sql.functions import expr, col, desc\n","\n","result = df_pt.join(df_sales, \"product_id\")\\\n",".groupBy(\"seller_id\", \"product_name\")\\\n",".agg(expr(\"sum(num_of_items_sold)\").alias(\"total_quantity\"))\\\n",".orderBy(desc(\"total_quantity\"))\\\n",".filter((col(\"seller_id\") <= 10) & (col(\"seller_id\") >= 1))\\\n",".limit(1)\\\n",".select(\"product_name\")\n","\n","result.show()\n","\n","# +-------------+\n","# | product_name|\n","# +-------------+\n","# |product_36658|\n","# +-------------+\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"fa7bec8e-f93d-48ff-af38-d395c6fe7422","showTitle":false,"title":""},"id":"QtinRRycxDBS"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------------+\n","|total_revenue|\n","+-------------+\n","|    160916699|\n","+-------------+\n","\n"]}],"source":["# (c) Compute the combined revenue earned from sellers where seller_id ranges from 1 to 500 inclusive. [3m]\n","# Your table should have 1 column(s): [total_revenue]\n","from pyspark.sql.functions import expr, col, sum as _sum\n","\n","result = df_pt.join(df_sales, \"product_id\")\\\n",".groupBy(\"seller_id\")\\\n",".agg(expr(\"sum(num_of_items_sold * price)\").alias(\"revenue\"))\\\n",".orderBy(desc(\"revenue\"))\\\n",".filter((col(\"seller_id\") <= 500) & (col(\"seller_id\") >= 1))\\\n",".select(_sum(\"revenue\").alias(\"total_revenue\"))\n","\n","result.show()\n","\n","# +-------------+\n","# |total_revenue|\n","# +-------------+\n","# |    160916699|\n","# +-------------+\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"59c00e0a-34de-4614-b783-71beb7503716","showTitle":false,"title":""},"id":"jdG80LVMxnQf"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------+-----+\n","|product_name|price|\n","+------------+-----+\n","| product_106|  200|\n","| product_117|  200|\n","| product_363|  200|\n","| product_712|  200|\n","| product_843|  200|\n","| product_897|  200|\n","| product_923|  200|\n","|product_1466|  200|\n","|product_1507|  200|\n","|product_1514|  200|\n","+------------+-----+\n","\n"]}],"source":["# (d) Among sellers with rating >= 4 who have achieved a combined number of products sold >= 3000, find out the top 10 most expensive product sold by any of the sellers. (If there are multiple products at the same price, please sort them in ascending order of product_id) [8m]\n","# Your table should have 1 column(s): [product_name]\n","# To get the full mark, your query should not run for more than 1 min\n","\n","from pyspark.sql.functions import expr, desc, asc, col, sum as _sum\n","\n","df_max_num_by_seller = df_sales.join(\n","    df_seller.filter(col(\"rating\") >= 4),\n","    on=\"seller_id\",\n","    how=\"inner\"\n",").groupBy(\"seller_id\")\\\n",".agg(expr(\"sum(num_of_items_sold)\").alias(\"total_num_of_items_per_seller\"))\\\n",".orderBy(desc(\"total_num_of_items_per_seller\"))\\\n",".filter(col(\"total_num_of_items_per_seller\") >= 3000)\\\n",".select(\"*\")\n","\n","df_result = df_max_num_by_seller.join(df_sales, on=[\"seller_id\"], how=\"left\") \\\n","    .join(df_pt, on=[\"product_id\"], how=\"left\")\\\n","    .select(\"product_name\", \"price\")\\\n","    .distinct()\\\n","    .orderBy(desc(\"price\"), asc(\"product_id\"))\\\n","    .limit(10)\\\n","    .select(\"product_name\", \"price\")\n","\n","df_result.show()\n","\n","# +------------+-----+\n","# |product_name|price|\n","# +------------+-----+\n","# | product_106|  200|\n","# | product_117|  200|\n","# | product_363|  200|\n","# | product_712|  200|\n","# | product_843|  200|\n","# | product_897|  200|\n","# | product_923|  200|\n","# |product_1466|  200|\n","# |product_1507|  200|\n","# |product_1514|  200|\n","# +------------+-----+\n"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"cs5245_a2_databricks_ A0255967J","notebookOrigID":2659203281378118,"widgets":{}},"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
